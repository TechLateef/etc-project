{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Will be performing Web scraping in this project on banks\n",
    "\n",
    "## process\n",
    "* Extract the data from the web\n",
    "* Transform that data \n",
    "* Load the data to sqlite3 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the relevant packages\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all url and files that will be needed through out the project including variables are all definde below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://web.archive.org/web/20230908091635 /https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
    "# initial table attribute to be fetch from the web\n",
    "table_attribute = ['Name','MC_USD_Billion']\n",
    "# Final table attribute \n",
    "ftable_attribute =['Name','MC_USD_Billion','MC_GBP_Billion','MC_EUR_Billion','MC_INR_Billion']\n",
    "# where to save the file as csv\n",
    "target_file = './Largest_bank_data.csv'\n",
    "# database name to be use \n",
    "db_name = 'Banks.db'\n",
    "# table name where the data will be stored in db\n",
    "table_name='Largest_banks'\n",
    "# log file \n",
    "log_file = 'code_log.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # rate file that contain rate of some currency to dollars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_file = pd.read_csv('./exchange_rate.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # convert the exchange rate read above to to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rate = rate_file.set_index('Currency').to_dict()['Rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #Create the logfile which will handle writing the process with time in a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(message):\n",
    "    timestamp_format = '%Y-%d-%D-%H:%M:%S'\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(timestamp + \", \" + message + \"\\n\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This part is where we extract the date from the url we declare at the top level using requests & BeautifulSoup\n",
    "\n",
    "#### steps in this functions are \n",
    "* we fetch the page from the url as text\n",
    "* we fetch the html contents using Beautiful soup\n",
    "* we define our dataframe\n",
    "* then we fetch all tables in the html\n",
    "* we notice that the table which we find want to fetch data from is at index 0 so we fetch all row in that index\n",
    "* we now loop through the table row(tr) \n",
    "* we fetch all data(td) and indicate it as col \n",
    "* we check if col id not 0 we loop through table row (tr) to fetch data in each row \n",
    "* then we store them in diction \n",
    "* then we create a dataframe with that dictionary of data\n",
    "* lastly we joing the new dataframe created with the df created in line 3 inside the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(url, table_attribute):\n",
    "    page = requests.get(url).text\n",
    "    html = BeautifulSoup(page, 'html.parser')\n",
    "    df = pd.DataFrame(columns=table_attribute)\n",
    "    tables = html.find_all('tbody')\n",
    "    rows = tables[1].find_all('tr')\n",
    "    for row in rows:\n",
    "\n",
    "        if col:\n",
    "            col = row.find_all('td')\n",
    "            name = str(col[1].find_all('a')[1].text)\n",
    "            mc_usd_billion_str = col[2].contents[0].strip().replace('\\n', ',')\n",
    "            mc_usd_billion_str = mc_usd_billion_str.replace(',', '')\n",
    "            data_dic = {'Name': name,\n",
    "                        'MC_USD_Billion': float(mc_usd_billion_str)}\n",
    "            df1 = pd.DataFrame(data_dic, index=[0])\n",
    "            df = pd.concat([df, df1], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #TRansform the data in billion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df, csv_path):\n",
    "    df['MC_GBP_Billion'] = [\n",
    "        np.round(x * exchange_rate['GBP'], 2) for x in df['MC_USD_Billion']]\n",
    "    df['MC_INR_Billion'] = [\n",
    "        np.round(x * exchange_rate['INR'], 2) for x in df['MC_USD_Billion']]\n",
    "    df['MC_EUR_Billion'] = [\n",
    "        np.round(x * exchange_rate['EUR'], 2) for x in df['MC_USD_Billion']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_csv(df, output_path):\n",
    "    df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data into db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_db(df, sql_connection, table_name):\n",
    "    df.to_sql(table_name, sql_connection, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a function for running query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query_statement, sql_connection):\n",
    "    print(query_statement)\n",
    "    query_output = pd.read_sql(query_statement, sql_connection)\n",
    "    print(query_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '5,742.86'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Log the beginning of the Extraction process \u001b[39;00m\n\u001b[1;32m      5\u001b[0m log_progress(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtract phase Started\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m----> 6\u001b[0m extracted_data \u001b[38;5;241m=\u001b[39m \u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtable_attribute\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Log the completion of the Extraction process \u001b[39;00m\n\u001b[1;32m      9\u001b[0m log_progress(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtract phase Ended\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n",
      "Cell \u001b[0;32mIn[27], line 10\u001b[0m, in \u001b[0;36mextract\u001b[0;34m(url, table_attribute)\u001b[0m\n\u001b[1;32m      8\u001b[0m col \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m col:\n\u001b[0;32m---> 10\u001b[0m     data_dic \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(col[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtext), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMC_USD_Billion\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m}\n\u001b[1;32m     12\u001b[0m     df1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data_dic, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     13\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, df1], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '5,742.86'"
     ]
    }
   ],
   "source": [
    "# Log the initialization of the ETL process \n",
    "log_progress(\"ETL Job Started\") \n",
    " \n",
    "# Log the beginning of the Extraction process \n",
    "log_progress(\"Extract phase Started\") \n",
    "extracted_data = extract(url,table_attribute) \n",
    " \n",
    "# Log the completion of the Extraction process \n",
    "log_progress(\"Extract phase Ended\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Log the beginning of the Transformation process \n",
    "log_progress(\"Transform phase Started\") \n",
    "transformed_data = transform(extracted_data,target_file) \n",
    "print(\"Transformed Data\") \n",
    "print(transformed_data) \n",
    "\n",
    "# Log the completion of the Transformation process \n",
    "log_progress(\"Transform phase Ended\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Log the beginning of the Loading process \n",
    "log_progress(\"Load phase Started\") \n",
    "load_to_csv(transformed_data,target_file)\n",
    "\n",
    "# Log the completion of the Loading process \n",
    "log_progress(\"Load phase Ended\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(db_name)\n",
    "\n",
    " \n",
    "# Log the beginning of the Loading process \n",
    "log_progress(\"Load to db phase Started\") \n",
    "load_to_db(transformed_data,conn,table_name) \n",
    " \n",
    "# Log the completion of the Loading process \n",
    "log_progress(\"Load to db phase Ended\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_query(f\"SELECT * FROM Largest_banks\",conn)\n",
    "run_query(f\"SELECT AVG(MC_GBP_Billion) FROM Largest_banks\",conn)\n",
    "run_query(f\"SELECT Name from Largest_banks LIMIT 5\",conn)\n",
    "# Log the completion of the ETL pr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArewaDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
